{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tflearn\n",
    "from tflearn.layers.core import input_data, dropout, fully_connected\n",
    "from tflearn.layers.conv import conv_2d, max_pool_2d\n",
    "from tflearn.layers.normalization import local_response_normalization\n",
    "from tflearn.layers.estimator import regression\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from os import walk\n",
    "from PIL import Image\n",
    "\n",
    "path = 'figures'\n",
    "data = {}\n",
    "for (dirpath, dirnames, filenames) in walk(path):\n",
    "    for dirname in dirnames:\n",
    "        if dirname not in data:\n",
    "            data[dirname] = []\n",
    "        \n",
    "        for (figpath, dontcare, figs) in walk(dirpath + '/' + dirname):\n",
    "            for fig in figs:\n",
    "                figImage = Image.open(figpath + '/' + fig).convert('L')    \n",
    "                data[dirname].append(figImage.resize((28, 28), Image.ANTIALIAS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def to2d(img):\n",
    "    array = np.asarray(img)\n",
    "    x = []\n",
    "    for row in array:\n",
    "        we = []\n",
    "        x.append(we)\n",
    "        for value in row:\n",
    "            we.append(1-value/255)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def one_hot(data_set):\n",
    "    i = 0\n",
    "    output = len(data_set) + 1\n",
    "    X = []\n",
    "    Y = []\n",
    "    Z = []\n",
    "    for fig in data_set:   \n",
    "        i = i + 1\n",
    "        oh = np.zeros(output, dtype=np.float64)\n",
    "        oh[i] = 1 if fig == 'circle' else 0\n",
    "        for img in data_set[fig]:\n",
    "            for r in range(5):\n",
    "                X.append(to2d(img))\n",
    "                Y.append(oh)\n",
    "                Z.append(img)\n",
    "    return np.array(X, dtype=np.float64).reshape([-1, 28, 28, 1]), np.array(Y, dtype=np.float64), Z\n",
    "\n",
    "X,Y,Z = one_hot(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "shuf = list(zip(X, Y,Z))\n",
    "random.shuffle(shuf)\n",
    "X = [e[0] for e in shuf]\n",
    "Y = [e[1] for e in shuf]\n",
    "Z = [e[2] for e in shuf]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch = 50\n",
    "# # graph = tf.Graph() \n",
    "# # with graph.as_default():\n",
    "#     network = input_data(shape=[None, 28, 28, 1], name='input', dtype=tf.float32)\n",
    "#     network = conv_2d(network, 32, 3, activation='relu', regularizer=\"L2\")\n",
    "#     network = max_pool_2d(network, 2)\n",
    "#     network = local_response_normalization(network)\n",
    "# #     network = conv_2d(network, 64, 3, activation='relu', regularizer=\"L2\")\n",
    "# #     network = max_pool_2d(network, 2)\n",
    "# #     network = local_response_normalization(network)\n",
    "# #     network = fully_connected(network, 128, activation='tanh')\n",
    "# #     network = dropout(network, 0.8)\n",
    "#     network = fully_connected(network, 256, activation='tanh')\n",
    "#     network = dropout(network, 0.8)\n",
    "#     network = fully_connected(network, 4, activation='softmax')\n",
    "#     network = regression(network, optimizer='SGD', learning_rate=0.5,\n",
    "#                              loss='categorical_crossentropy', name='target')\n",
    "#     gmodel = tflearn.DNN(network, tensorboard_verbose=3, tensorboard_dir='board')\n",
    "#     gmodel.fit({'input': X[:-batch]}, {'target': Y[:-batch]}, n_epoch=10,\n",
    "#                        validation_set=({'input': X[-batch:]}, {'target': Y[-batch:]}),\n",
    "#                        snapshot_step=100, show_metric=True, run_id='fig_net_51')\n",
    "    \n",
    "#     gmodel.evaluate({'input': X[:-batch]}, {'target': Y[:-batch]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "activations = ('relu','tanh')\n",
    "optimizers  = ('sgd', 'adam')\n",
    "losses      = ('categorical_crossentropy','whatever')\n",
    "regulizers  = ('L1','L2')\n",
    "\n",
    "def create_parameterized_network(params):\n",
    "    name = \"net_\" + str(params).replace('(','').replace(')','').replace(',','').replace(' ','')\n",
    "    print('Create network:' + name)\n",
    "    network = input_data(shape=[None, 28, 28, 1], name='input', dtype=tf.float32)\n",
    "    layer_n = 0\n",
    "    for p in params[:-1]:\n",
    "        layer_n = layer_n + 1\n",
    "        layer_type = p[0] \n",
    "        shape = p[1]\n",
    "        activation = activations[p[2]]\n",
    "        regulizer = regulizers[p[3]]\n",
    "        drpt = p[4]\n",
    "        fltr = p[5]\n",
    "        max_pool = p[6]\n",
    "        \n",
    "        if layer_type == 0:\n",
    "            layer_name = 'fc_' + str(layer_n)\n",
    "            print('Create layer {} with shape: {}, activation: {}, dropout: {}'\n",
    "                  .format(layer_name, shape, activation, drpt))\n",
    "            network = fully_connected(network, shape, \n",
    "                                      activation=activation, \n",
    "                                      name=layer_name)\n",
    "            network = dropout(network, drpt)\n",
    "        elif layer_type == 1:     \n",
    "            layer_name = 'conv_' + str(layer_n)\n",
    "            print('Create layer {} with shape: {}, activation: {}, regularizer: {}, filter: {}, max_pool: {}'\n",
    "                  .format(layer_name, shape, activation, regulizer, fltr, max_pool))\n",
    "            network = conv_2d(network, shape, fltr, \n",
    "                              activation=activation, \n",
    "                              regularizer=regulizer,\n",
    "                              name=layer_name)\n",
    "            network = max_pool_2d(network, p[6])\n",
    "            network = local_response_normalization(network) \n",
    "    \n",
    "    network = fully_connected(network, 4, activation='softmax', name='prob')\n",
    "    \n",
    "    optimizer=optimizers[params[-1][0]]\n",
    "    learning_rate=params[-1][1]\n",
    "    loss=losses[params[-1][2]]\n",
    "    print('Add regression {} at {} with {}'.format(optimizer, learning_rate, loss)\n",
    "                  .format(layer_name, shape, activation, regulizer, fltr, max_pool))\n",
    "    network = regression(network, \n",
    "                         optimizer=optimizer, \n",
    "                         learning_rate=learning_rate,\n",
    "                         loss=loss, \n",
    "                         name='target')\n",
    "    \n",
    "    return network, name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def learn(params, batch):\n",
    "    graph = tf.Graph() \n",
    "    with graph.as_default():\n",
    "            network, name = create_parameterized_network(params)\n",
    "            gmodel = tflearn.DNN(network, tensorboard_verbose=3, tensorboard_dir='mnist/board')\n",
    "            gmodel.fit({'input': X[:-batch]}, {'target': Y[:-batch]}, n_epoch=1,\n",
    "                       validation_set=({'input': X[-batch:]}, {'target': Y[-batch:]}),\n",
    "                       snapshot_step=100, show_metric=True, run_id=name)\n",
    "            return gmodel.evaluate({'input': X[:-batch]}, {'target': Y[:-batch]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 3  | total loss: \u001b[1m\u001b[32m0.28904\u001b[0m\u001b[0m | time: 2.636s\n",
      "| Adam | epoch: 001 | loss: 0.28904 - acc: 0.2915 -- iter: 192/255\n",
      "Training Step: 4  | total loss: \u001b[1m\u001b[32m0.07428\u001b[0m\u001b[0m | time: 4.285s\n",
      "| Adam | epoch: 001 | loss: 0.07428 - acc: 0.3424 | val_loss: 0.00003 - val_acc: 0.2200 -- iter: 255/255\n",
      "--\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-73:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\etashkinov\\appdata\\local\\programs\\python\\python35\\lib\\threading.py\", line 914, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"c:\\users\\etashkinov\\appdata\\local\\programs\\python\\python35\\lib\\threading.py\", line 862, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"c:\\users\\etashkinov\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tflearn\\data_flow.py\", line 187, in fill_feed_dict_queue\n",
      "    data = self.retrieve_data(batch_ids)\n",
      "  File \"c:\\users\\etashkinov\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tflearn\\data_flow.py\", line 222, in retrieve_data\n",
      "    utils.slice_array(self.feed_dict[key], batch_ids)\n",
      "  File \"c:\\users\\etashkinov\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tflearn\\utils.py\", line 180, in slice_array\n",
      "    return [x[start] for x in X]\n",
      "  File \"c:\\users\\etashkinov\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tflearn\\utils.py\", line 180, in <listcomp>\n",
      "    return [x[start] for x in X]\n",
      "IndexError: index 28 is out of bounds for axis 0 with size 28\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0]\n"
     ]
    }
   ],
   "source": [
    "print(learn((\n",
    "    (1,32, 0,1,0,  3,2), \n",
    "    (1,64, 0,1,0,  3,2),\n",
    "    (0,128,1,0,0.8,0,0),\n",
    "    (0,256,1,0,0.8,0,0),\n",
    "    (1, 0.01, 0)\n",
    "), 50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(305, 28, 28, 1)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(X).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(305, 4)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(Y).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}